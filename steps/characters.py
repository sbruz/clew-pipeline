import shutil
import os
import json
import yaml
import base64
from PIL import Image
from pathlib import Path
import io
from datetime import datetime, timezone
from openai import OpenAI
from utils.supabase_client import get_supabase_client
from schemas.characters import (
    Names, Appearance, CharacterAppearanceSummary, CharactersInParagraph,
    AppearanceItem, CharacterRoles, CharacterMention, CharacterMentions
)


def load_config(config_path: str = "config.yaml") -> dict:
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def clean_characters_and_appearance(supabase, book_id):
    old_chars = supabase.table("books_characters").select(
        "id").eq("book_id", book_id).execute().data or []
    char_ids = [c["id"] for c in old_chars]
    if char_ids:
        supabase.table("characters_roles").delete().in_(
            "character_id", char_ids).execute()
        supabase.table("characters_appearance").delete().in_(
            "character_id", char_ids).execute()
        supabase.table("books_characters").delete().in_(
            "id", char_ids).execute()


def clean_roles(supabase, book_id):
    supabase.table("characters_roles").delete().eq(
        "book_id", book_id).execute()


def step_find_characters_and_appearance(book_id, data, paragraphs_with_id, supabase, client):
    characters_by_id = {}
    character_names_by_id = {}
    total_paragraphs = len(paragraphs_with_id)
    processed = 0

    for idx, para in enumerate(paragraphs_with_id, start=1):
        paragraph_num = idx
        para_text = para["text"]
        percent = idx * 100 // total_paragraphs
        print(
            f"[{idx}/{total_paragraphs}] ({percent}%) –ê–Ω–∞–ª–∏–∑ –∞–±–∑–∞—Ü–∞ {paragraph_num}...")

        known_characters_for_prompt = [
            {
                "id": char_id,
                "main": character_names_by_id[char_id].main,
                "additional_names": character_names_by_id[char_id].additional_names
            }
            for char_id in characters_by_id.keys()
        ]

        prompt_old = (
            f"–ö–Ω–∏–≥–∞: {data['title']}\n"
            f"–ê–≤—Ç–æ—Ä: {data['author']}\n"
            f"–ê–±–∑–∞—Ü: {para_text}\n"
            f"–¢–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {json.dumps(known_characters_for_prompt, ensure_ascii=False)}\n"
            "–ù–∞–π–¥–∏ –≤ –∞–±–∑–∞—Ü–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, —É –∫–æ—Ç–æ—Ä—ã—Ö –≤ —ç—Ç–æ–º –∞–±–∑–∞—Ü–µ –µ—Å—Ç—å –ø—Ä—è–º–æ–µ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –∏–ª–∏ –æ–¥–µ–∂–¥—ã."
            "–ï—Å–ª–∏ —Ç–∞–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–æ —Å—Ö–µ–º–µ CharactersInParagraph.\n"
            "–ù–µ —É—á–∏—Ç—ã–≤–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –Ω–æ—Å–∏—Ç —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä, –Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≥–ª—É–ø—ã–º –∏–ª–∏ —É–º–Ω–∏—Ü–µ–π."
            "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤–µ—Ä–Ω–∏:\n"
            "1. –û–±—ä–µ–∫—Ç Names —Å –æ—Å–Ω–æ–≤–Ω—ã–º –∏–º–µ–Ω–µ–º –∏ –≤—Å–µ–º–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø—Ä–æ–∑–≤–∏—â–∞–º–∏/–∏–º–µ–Ω–∞–º–∏ (–∏–∑–º–µ–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–º—è –∏ –¥–æ–±–∞–≤—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ, –µ—Å–ª–∏ –≤ –∞–±–∑–∞—Ü–µ –ø–æ—è–≤–∏–ª–æ—Å—å —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –∏–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂ –ø—Ä–µ–æ–±—Ä–∞–∑–∏–ª—Å—è –≤ –Ω–æ–≤–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂).\n"
            "2. Appearance —Å —Ü–∏—Ç–∞—Ç–æ–π, –∫–∞—Å–∞—é—â–µ–π—Å—è –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –≤ —ç—Ç–æ–º –∞–±–∑–∞—Ü–µ. –ü–∏—à–∏ —Ç–æ–ª—å–∫–æ –≤—ã–∂–∏–º–∫—É –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∂–µ–ª—Ç–æ–µ –ø–ª–∞—Ç—å–µ, –∫—Ä–∞—Å–∏–≤—ã–π, –≤—ã—Å–æ–∫–∏–π). –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–π –¥–µ—Ç–∞–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ –∞–±–∑–∞—Ü–µ.\n"
            "–ï—Å–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂ –Ω–æ–≤—ã–π, –≤–µ—Ä–Ω–∏ id=0. –í–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤, —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ CharactersInParagraph."
        )

        prompt = (
            f"–ö–Ω–∏–≥–∞: {data['title']}\n"
            f"–ê–≤—Ç–æ—Ä: {data['author']}\n"
            f"–ê–±–∑–∞—Ü: {para_text}\n"
            f"–¢–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {json.dumps(known_characters_for_prompt, ensure_ascii=False)}\n"
            "–ù–∞–π–¥–∏ –≤ –∞–±–∑–∞—Ü–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º–∏ –¥–ª—è —Å—é–∂–µ—Ç–∞ –∫–Ω–∏–≥–∏. –ú–∞–ª–æ–∑–Ω–∞—á–∏–º—ã—Ö –≤—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –ø—Ä–æ–ø—É—Å–∫–∞–π."
            "–ï—Å–ª–∏ —Ç–∞–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–æ —Å—Ö–µ–º–µ CharactersInParagraph.\n"
            "–ù–µ —É—á–∏—Ç—ã–≤–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –Ω–æ—Å–∏—Ç —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä, –Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≥–ª—É–ø—ã–º –∏–ª–∏ —É–º–Ω–∏—Ü–µ–π."
            "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤–µ—Ä–Ω–∏:\n"
            "1. –û–±—ä–µ–∫—Ç Names —Å –æ—Å–Ω–æ–≤–Ω—ã–º –∏–º–µ–Ω–µ–º –∏ –≤—Å–µ–º–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø—Ä–æ–∑–≤–∏—â–∞–º–∏/–∏–º–µ–Ω–∞–º–∏ (–∏–∑–º–µ–Ω–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–º—è –∏ –¥–æ–±–∞–≤—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ, –µ—Å–ª–∏ –≤ –∞–±–∑–∞—Ü–µ –ø–æ—è–≤–∏–ª–æ—Å—å —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –∏–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂ –ø—Ä–µ–æ–±—Ä–∞–∑–∏–ª—Å—è –≤ –Ω–æ–≤–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂).\n"
            "2. Appearance —Å —Ü–∏—Ç–∞—Ç–æ–π, –∫–∞—Å–∞—é—â–µ–π—Å—è –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –≤ —ç—Ç–æ–º –∞–±–∑–∞—Ü–µ. –ü–∏—à–∏ —Ç–æ–ª—å–∫–æ –≤—ã–∂–∏–º–∫—É –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∂–µ–ª—Ç–æ–µ –ø–ª–∞—Ç—å–µ, –∫—Ä–∞—Å–∏–≤—ã–π, –≤—ã—Å–æ–∫–∏–π). –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–π –¥–µ—Ç–∞–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ –∞–±–∑–∞—Ü–µ.\n"
            "–ï—Å–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂ –Ω–æ–≤—ã–π, –≤–µ—Ä–Ω–∏ id=0. –í–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤, —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ CharactersInParagraph."
        )

        try:
            completion = client.beta.chat.completions.parse(
                model="gpt-4.1",
                messages=[{"role": "user", "content": prompt}],
                response_format=CharactersInParagraph
            )
            response_obj = completion.choices[0].message.parsed
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –Ω–∞ –∞–±–∑–∞—Ü–µ {idx}: {e}")
            continue

        new_person_count = 0
        for char_obj in response_obj.characters:
            names = char_obj.names
            appearance = char_obj.appearance
            names_json = names.json()
            appearance_json = appearance.json()

            if char_obj.id == 0:
                insert_result = supabase.table("books_characters").insert({
                    "book_id": book_id,
                    "name": names_json
                }).execute()
                char_id = insert_result.data[0]["id"]
                summary = CharacterAppearanceSummary(
                    appearances=[AppearanceItem(
                        paragraph=paragraph_num, appearance=appearance)]
                )
                characters_by_id[char_id] = summary
                character_names_by_id[char_id] = names
                new_person_count += 1
            else:
                char_id = char_obj.id
                summary = characters_by_id.get(char_id)
                if summary:
                    prev_names = character_names_by_id[char_id]
                    if set(names.additional_names) != set(prev_names.additional_names) or names.main != prev_names.main:
                        character_names_by_id[char_id] = names
                        supabase.table("books_characters").update({
                            "name": names_json
                        }).eq("id", char_id).execute()
                    summary.appearances.append(AppearanceItem(
                        paragraph=paragraph_num, appearance=appearance))
                else:
                    char_row = supabase.table("books_characters").select(
                        "*").eq("id", char_id).single().execute().data
                    char_names = Names.parse_raw(char_row["name"])
                    summary = CharacterAppearanceSummary(
                        appearances=[AppearanceItem(
                            paragraph=paragraph_num, appearance=appearance)]
                    )
                    characters_by_id[char_id] = summary
                    character_names_by_id[char_id] = char_names

            if any([appearance.basic, appearance.face, appearance.body, appearance.hair, appearance.clothes]):
                supabase.table("characters_appearance").insert({
                    "character_id": char_id,
                    "paragraph": paragraph_num,
                    "appearance": appearance_json
                }).execute()

        print(
            f"    ‚úÖ {len(response_obj.characters)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, –Ω–æ–≤—ã—Ö: {new_person_count}")
        processed += 1

    # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏
    print("\nüîç –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞...")
    all_chars = supabase.table("books_characters").select(
        "id", "name").eq("book_id", book_id).execute().data or []
    for i, char in enumerate(all_chars, 1):
        char_id = char["id"]
        names = Names.parse_raw(char["name"])
        appearances_rows = supabase.table("characters_appearance").select(
            "paragraph, appearance").eq("character_id", char_id).order("paragraph").execute().data or []
        appearances = [
            AppearanceItem(paragraph=int(
                row["paragraph"]), appearance=Appearance.parse_raw(row["appearance"]))
            for row in appearances_rows
        ]

        prompt = (
            f"–ö–Ω–∏–≥–∞: {data['title']}\n"
            f"–ê–≤—Ç–æ—Ä: {data['author']}\n"
            f"–ò–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞: {names.main}\n"
            f"–í–æ—Ç –∏—Å—Ç–æ—Ä–∏—è —É—Ç–æ—á–Ω–µ–Ω–∏–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –ø–æ —Ö–æ–¥—É –∫–Ω–∏–≥–∏ –ø–æ –∞–±–∑–∞—Ü–∞–º:\n"
            f"{json.dumps([ai.dict() for ai in appearances], ensure_ascii=False)}\n"
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –≥–µ—Ä–æ—è –ø–æ –º–µ—Ä–µ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è. "
            "–í–µ—Ä–Ω–∏ –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É CharacterAppearanceSummary, –≥–¥–µ appearances ‚Äî —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∫–ª—é—á–∞–º–∏ paragraph (–Ω–æ–º–µ—Ä –∞–±–∑–∞—Ü–∞) –∏ appearance (–æ–±—ä–µ–∫—Ç Appearance).\n"
            "–û–±—ä–µ–∫—Ç Appearance - —ç—Ç–æ —Å–æ–±—Ä–∞–Ω–Ω—ã–π –ø–æ –≤—Å–µ–º –∞–±–∑–∞—Ü–∞–º –æ–±—Ä–∞–∑ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞.\n"
            "–ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –≤ –∞–±–∑–∞—Ü–µ 1 –º—ã —É–∑–Ω–∞–µ–º, —á—Ç–æ –ø–µ—Ä—Å–æ–Ω–∞–∂ –∫—Ä–∞—Å–∏–≤—ã–π, –≤–æ 2 –∞–±–∑–∞—Ü–µ, —á—Ç–æ —É –Ω–µ–≥–æ –¥–ª–∏–Ω–Ω—ã–µ —á–µ—Ä–Ω—ã–µ –≤–æ–ª–æ—Å—ã, –∞ –≤ —Ç—Ä–µ—Ç—å–µ–º, —á—Ç–æ –æ–Ω –æ–¥–µ—Ç –≤ –∂–µ–ª—Ç–æ–µ –ø–ª–∞—Ç—å–µ, —Ç–æ –ø–∏—à–µ–º —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∫ 1 –∞–±–∑–∞—Ü—É, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω —Ç–∞–∫ –≤—ã–≥–ª—è–¥–µ–ª —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞.\n"
            "–î–∞–ª–µ–µ, –µ—Å–ª–∏ –µ–≥–æ –≤–Ω–µ—à–Ω–æ—Å—Ç—å –º–µ–Ω—è–µ—Ç—Å—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ 10 –∞–±–∑–∞—Ü–µ –æ–Ω –∑–∞–ø–ª–µ–ª–µ–ª –≤–æ–ª–æ—Å—ã –≤ –∫–æ—Å–∏—á–∫—É, —Ç–æ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å—É–º–º–∞—Ä–Ω–æ–π –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–∏–≤—è–∑–∞—Ç—å –∫ —ç—Ç–æ–º—É –∞–±–∑–∞—Ü—É.\n"
            "–°–æ–∑–¥–∞–π –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –¥–ª—è –∞–±–∑–∞—Ü–∞ 1 - —Ç–æ, –∫–∞–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂ –≤—ã–≥–ª—è–¥–∏—Ç –≤ –Ω–∞—á–∞–ª–µ –∫–Ω–∏–≥–∏.\n"
            "–î–æ–ø–æ–ª–Ω–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –ø–æ–ª–µ–π —Å —É—á–µ—Ç–æ–º –æ–±—â–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤–Ω–µ—à–Ω–æ—Å—Ç–∏, —Ä–æ–ª–∏ –≤ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–∏, –ø—Ä–∏–≤—ã—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ.\n"
            "–î–æ–¥—É–º–∞–π —Ü–≤–µ—Ç–∞ –∏ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø–æ–≤—Ç–æ—Ä—è–µ–º–æ—Å—Ç–∏ –Ω–∞ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è—Ö.\n"
            "–û–ø–∏—Å—ã–≤–∞–π –≤–Ω–µ—à–Ω–æ—Å—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Ç–∞–∫, –∫–∞–∫ –µ—Å–ª–∏ –±—ã –æ–Ω–∏ –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –¥–∞–≤–∞–ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é, –Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞ —à–æ—É Celebrity Big Brother ‚Äì¬†–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ —Å—Ç–∞—Ä–∞—é—Ç—Å—è —Å–∫—Ä—ã—Ç—å —Å–≤–æ–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏ –∏ —Å–∫—Ä—ã—Ç—ã–µ –º–æ—Ç–∏–≤—ã, –∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –±–æ–ª–µ–µ –æ—Ç–∫—Ä—ã—Ç—ã –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã."
        )

        try:
            completion = client.beta.chat.completions.parse(
                model="gpt-4.1",
                messages=[{"role": "user", "content": prompt}],
                response_format=CharacterAppearanceSummary
            )
            summary = completion.choices[0].message.parsed
        except Exception as e:
            print(
                f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏—Å—Ç–æ—Ä–∏–∏ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ '{names.main}': {e}")
            continue

        summary_dict = summary.model_dump()
        summary_json = json.dumps(summary_dict, indent=2, ensure_ascii=False)
        supabase.table("books_characters").update({
            "appearance": summary_json
        }).eq("id", char_id).execute()
        print(
            f"    üßë‚Äçüî¨ [{i}/{len(all_chars)}] –ò—Ç–æ–≥–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è '{names.main}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")

    print(
        f"\nüèÅ –ì–æ—Ç–æ–≤–æ! –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {processed} –∞–±–∑–∞—Ü–µ–≤ –∏ {len(all_chars)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∫–Ω–∏–≥–∏ '{data['title']}'.")

    # === –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–≤—ã–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∞–±–∑–∞—Ü –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ ===
    print("üîé –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–±–∑–∞—Ü—ã –ø–µ—Ä–≤–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å –∏–º–µ–Ω–∞–º–∏
    all_chars_for_mentions = supabase.table("books_characters").select(
        "id", "name").eq("book_id", book_id).execute().data or []
    characters_with_names = [
        {"id": c["id"], "names": Names.parse_raw(c["name"]).dict()}
        for c in all_chars_for_mentions
    ]

    book_text = ""
    for idx, para in enumerate(paragraphs_with_id, start=1):
        book_text += f"{idx}. {para['text']}\n"

    mentions_prompt = (
        f"–ö–Ω–∏–≥–∞: {data['title']}\n"
        f"–ê–≤—Ç–æ—Ä: {data['author']}\n"
        f"–¢–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ —Å –Ω–æ–º–µ—Ä–∞–º–∏ –∞–±–∑–∞—Ü–µ–≤:\n{book_text}\n"
        f"–°–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {json.dumps(characters_with_names, ensure_ascii=False)}\n"
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ —É–∫–∞–∂–∏ –Ω–æ–º–µ—Ä –∞–±–∑–∞—Ü–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω –≤–ø–µ—Ä–≤—ã–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ (–∫–∞–∫ —á–∏—Å–ª–æ). "
        "–í–µ—Ä–Ω–∏ –æ–±—ä–µ–∫—Ç mentions ‚Äî —Å–ø–∏—Å–æ–∫ –∏–∑ CharacterMention —Å –ø–æ–ª—è–º–∏ id –∏ first_paragraph."
    )

    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4.1",
            messages=[{"role": "user", "content": mentions_prompt}],
            response_format=CharacterMentions
        )
        mentions_obj = completion.choices[0].message.parsed
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–µ—Ä–≤–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è: {e}")
        return

    print("üì• –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –ø–µ—Ä–≤—ã—Ö –∞–±–∑–∞—Ü–µ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É books_characters...")

    # –°–æ–±–µ—Ä—ë–º –≤—Å–µ first_paragraph
    used_paragraphs = set()
    updates = []
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á—Ç–æ–±—ã –æ–±—Ä–∞–±–æ—Ç–∫–∞ —à–ª–∞ –≤ –æ–¥–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –≤—Å–µ–≥–¥–∞
    mentions_sorted = sorted(mentions_obj.mentions, key=lambda x: x.id)
    for mention in mentions_sorted:
        first_para = mention.first_paragraph
        # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ == 1, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–∞ 1
        if first_para == 1:
            first_para += 1
        # –î–µ–ª–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–º —Å—Ä–µ–¥–∏ —É–∂–µ –≤—Å—Ç—Ä–µ—á–∞–≤—à–∏—Ö—Å—è
        while first_para in used_paragraphs:
            first_para += 1
        used_paragraphs.add(first_para)
        updates.append((mention.id, first_para))

    for char_id, para in updates:
        supabase.table("books_characters").update({
            "first_paragraph": para
        }).eq("id", char_id).execute()

    print("‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–µ—Ä–≤—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ books_characters!")


def step_roles(book_id, data, paragraphs_with_id, supabase, client):
    print("\nüß© –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π...")

    all_chars_for_roles = supabase.table("books_characters").select(
        "id", "name").eq("book_id", book_id).execute().data or []
    characters_list = [{"id": c["id"], "names": Names.parse_raw(
        c["name"]).dict()} for c in all_chars_for_roles]

    roles_prompt = (
        f"–ö–Ω–∏–≥–∞: {data['title']}\n"
        f"–ê–≤—Ç–æ—Ä: {data['author']}\n"
        f"–í–æ—Ç —Å–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {json.dumps(characters_list, ensure_ascii=False)}\n"
        "–ù–∞–∑–æ–≤–∏ id –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —Ä–æ–ª–µ–π: hero (main protagonist), antagonist (main opponent), ally (helps the hero, provides wisdom), trickster (minor Antagonist, brings chaos), victim (suffers to further the plot).\n"
        "–ï—Å–ª–∏ —Ä–æ–ª—å –Ω–µ –Ω–∞—à–ª–∞—Å—å, –æ—Å—Ç–∞–≤—å None. –í–µ—Ä–Ω–∏ –æ–±—ä–µ–∫—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ CharacterRoles."
    )

    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4.1",
            messages=[{"role": "user", "content": roles_prompt}],
            response_format=CharacterRoles
        )
        roles_obj = completion.choices[0].message.parsed
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ä–æ–ª–µ–π: {e}")
        return

    print("üì• –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–æ–ª–∏ –≤ –ë–î...")

    # –°–æ–±–µ—Ä—ë–º –≤—Å–µ id –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
    all_ids = set(c["id"] for c in all_chars_for_roles)

    # –°–ª–æ–≤–∞—Ä—å: —Ä–æ–ª—å -> id –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
    roles_map = {
        "hero": roles_obj.hero,
        "ally": roles_obj.ally,
        "antagonist": roles_obj.antagonist,
        "trickster": roles_obj.trickster,
        "victim": roles_obj.victim,
    }

    # id –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å —Ü–µ–ª–µ–≤—ã–º–∏ —Ä–æ–ª—è–º–∏
    assigned_ids = set(x for x in roles_map.values() if x is not None)
    # –≤—Å–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –±–µ–∑ —Ü–µ–ª–µ–≤—ã—Ö —Ä–æ–ª–µ–π -> —Ä–æ–ª—å "other"
    other_ids = all_ids - assigned_ids

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–ª–µ–≤—ã–µ —Ä–æ–ª–∏
    for role, char_id in roles_map.items():
        if char_id is not None:
            exists = supabase.table("characters_roles").select("id").eq(
                "book_id", book_id).eq("character_id", char_id).execute().data
            role_values = {
                "hero": False,
                "ally": False,
                "antagonist": False,
                "trickster": False,
                "victim": False,
                "other": False
            }
            role_values[role] = True

            if exists:
                supabase.table("characters_roles").update(role_values).eq(
                    "book_id", book_id).eq("character_id", char_id).execute()
            else:
                supabase.table("characters_roles").insert({
                    "book_id": book_id,
                    "character_id": char_id,
                    **role_values
                }).execute()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º "other" —Ä–æ–ª—å –¥–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
    for char_id in other_ids:
        exists = supabase.table("characters_roles").select("id").eq(
            "book_id", book_id).eq("character_id", char_id).execute().data
        role_values = {
            "hero": False,
            "ally": False,
            "antagonist": False,
            "trickster": False,
            "victim": False,
            "other": True
        }
        if exists:
            supabase.table("characters_roles").update(role_values).eq(
                "book_id", book_id).eq("character_id", char_id).execute()
        else:
            supabase.table("characters_roles").insert({
                "book_id": book_id,
                "character_id": char_id,
                **role_values
            }).execute()

    print("üîé –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–±–∑–∞—Ü—ã –ø–µ—Ä–≤–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π...")

    # –°–æ–∑–¥–∞—ë–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–≤—Å–µ, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Å —Ä–æ–ª—è–º–∏)
    characters_with_roles = [
        {"id": c["id"], "names": c["names"]}
        for c in characters_list
    ]

    book_text = ""
    for idx, para in enumerate(paragraphs_with_id, start=1):
        book_text += f"{idx}. {para['text']}\n"

    mentions_prompt = (
        f"–ö–Ω–∏–≥–∞: {data['title']}\n"
        f"–ê–≤—Ç–æ—Ä: {data['author']}\n"
        f"–¢–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ —Å –Ω–æ–º–µ—Ä–∞–º–∏ –∞–±–∑–∞—Ü–µ–≤:\n{book_text}\n"
        f"–°–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {json.dumps(characters_with_roles, ensure_ascii=False)}\n"
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ —É–∫–∞–∂–∏ –Ω–æ–º–µ—Ä –∞–±–∑–∞—Ü–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω –≤–ø–µ—Ä–≤—ã–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ (–∫–∞–∫ —á–∏—Å–ª–æ). "
        "–í–µ—Ä–Ω–∏ –æ–±—ä–µ–∫—Ç mentions ‚Äî —Å–ø–∏—Å–æ–∫ –∏–∑ CharacterMention —Å –ø–æ–ª—è–º–∏ id –∏ first_paragraph."
    )

    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4.1",
            messages=[{"role": "user", "content": mentions_prompt}],
            response_format=CharacterMentions
        )
        mentions_obj = completion.choices[0].message.parsed
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–µ—Ä–≤–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è: {e}")
        return

    print("üì• –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –ø–µ—Ä–≤—ã—Ö –∞–±–∑–∞—Ü–µ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É characters_roles...")

    # –°–æ–±–µ—Ä—ë–º –≤—Å–µ first_paragraph
    used_paragraphs = set()
    updates = []
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á—Ç–æ–±—ã –æ–±—Ä–∞–±–æ—Ç–∫–∞ —à–ª–∞ –≤ –æ–¥–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –≤—Å–µ–≥–¥–∞
    mentions_sorted = sorted(mentions_obj.mentions, key=lambda x: x.id)
    for mention in mentions_sorted:
        first_para = mention.first_paragraph
        # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ == 1, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–∞ 1
        if first_para == 1:
            first_para += 1
        # –î–µ–ª–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–º —Å—Ä–µ–¥–∏ —É–∂–µ –≤—Å—Ç—Ä–µ—á–∞–≤—à–∏—Ö—Å—è
        while first_para in used_paragraphs:
            first_para += 1
        used_paragraphs.add(first_para)
        updates.append((mention.id, first_para))

    for char_id, para in updates:
        supabase.table("characters_roles").update({
            "first_paragraph": para
        }).eq("book_id", book_id).eq("character_id", char_id).execute()

    print("‚úÖ –†–æ–ª–∏ –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–µ—Ä–≤—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")


def create_resized_buffer(image_path):
    img = Image.open(image_path)
    w, h = img.size
    if w >= h:
        new_w, new_h = 512, int(h * (512 / w))
    else:
        new_h, new_w = 512, int(w * (512 / w))
    img = img.resize((new_w, new_h))
    buf = io.BytesIO()
    img.save(buf, format="WEBP")
    buf.seek(0)
    img.close()
    return ("image.webp", buf)


def step_draw(book_id, data, paragraphs_with_id, supabase, client):
    print("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π...")

    # --- Patch: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ chapters ---
    if "chapters" in data:
        chapters = data["chapters"]
    elif "text_by_chapters" in data:
        chapters = json.loads(data["text_by_chapters"])["chapters"]
    else:
        raise KeyError(
            "–í –æ–±—ä–µ–∫—Ç–µ data –Ω–µ—Ç –∫–ª—é—á–∞ chapters –∏–ª–∏ text_by_chapters")

    title = data['title']
    author = data['author']
    all_chars = supabase.table("books_characters").select(
        "id", "name", "appearance", "first_paragraph").eq("book_id", book_id).execute().data or []
    characters = []
    for c in all_chars:
        names = Names.parse_raw(c["name"])
        appearance_data = None
        if c.get("appearance"):
            try:
                appearance_data = json.loads(c["appearance"])
            except Exception:
                appearance_data = None
        characters.append({
            "id": c["id"],
            "names": names,
            "appearance_data": appearance_data,
            "first_paragraph": c.get("first_paragraph")
        })

    config = load_config()
    emotions_config = config.get("characters_emotions", {})
    emotions = [k for k, v in emotions_config.items() if v]
    print(f"–≠–º–æ—Ü–∏–∏: {emotions}")

    input_folder = Path("./export/previews")
    cover_path = input_folder / f"book_{book_id}.webp"

    # –ü–∞–ø–∫–∏
    out_dir = Path(f"./characters/book{book_id}")
    out_dir.mkdir(parents=True, exist_ok=True)
    export_dir = Path("./export/characters")
    export_dir.mkdir(parents=True, exist_ok=True)

    style = (
        "Transparent background; stylized digital character rendering; character shown from the waist up; directly facing the viewer with a clear, confident gaze; realistic anatomy with polished, high-definition finish ‚Äî smooth skin, sharp clothing detail, subtle specular light on hair and fabric; bold color grading with warm highlights and cinematic shadow; facial features fully visible and expressive, with personality-driven attitude; background fully transparent, characters cleanly cut out with soft rim light or drop shadow for depth; evokes modern, attitude-rich, polished realism in a format ready for covers, avatars, or motion graphics."
    )

    model = "gpt-image-1"
    size = "1024x1024"

    # –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≥–ª–∞–≤—ã –∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –≤ –≥–ª–∞–≤–µ –ø–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–º—É –∏–Ω–¥–µ–∫—Å—É
    para_map = {}
    idx_counter = 1
    for chapter in chapters:
        chapter_number = chapter["chapter_number"]
        for idx, paragraph in enumerate(chapter["paragraphs"], start=1):
            para_map[idx_counter] = (chapter_number, idx)
            idx_counter += 1

    for char in characters:
        char_id = char["id"]
        names = char["names"]
        first_paragraph = char.get("first_paragraph")
        print(f"\nüßë –ü–µ—Ä—Å–æ–Ω–∞–∂: {names.main}")

        char_folder = out_dir
        version = 1
        existing_versions = []
        for fname in char_folder.glob(f"{char_id}_p*_v*_*.webp"):
            stem = fname.stem
            try:
                v = int(stem.split("_v")[1].split("_")[0])
                existing_versions.append(v)
            except Exception:
                continue
        if existing_versions:
            version = max(existing_versions) + 1
        print(f"–í–µ—Ä—Å–∏—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π: {version}")

        appearances = []
        if char["appearance_data"] and "appearances" in char["appearance_data"]:
            for a in char["appearance_data"]["appearances"]:
                para = a.get("paragraph")
                appearance = a.get("appearance")
                appearances.append((para, appearance))
        else:
            print(f"  –ù–µ—Ç appearance –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {names.main}")
            continue

        for para_num, appearance in appearances:
            if para_num > 1:
                continue

            first_emotion = True
            for emotion_code in emotions:
                files_for_openai = []

                if first_emotion:
                    prompt = (
                        f"–ù–∞—Ä–∏—Å—É–π –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –ø–æ –º–æ—Ç–∏–≤–∞–º –∫–Ω–∏–≥–∏ '{title}' –∞–≤—Ç–æ—Ä–∞ {author}.\n"
                        f"–ò–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞: {names.main}.\n"
                        f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º, –µ—Å–ª–∏ –æ–Ω–∏ –¥–∞–Ω—ã.\n"
                        f"–ù–æ —É—á–∏—Ç—ã–≤–∞–π –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–æ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –ø–æ —Ö–æ–¥—É –∫–Ω–∏–≥–∏ (–¥–ª—è –∞–±–∑–∞—Ü–∞ {para_num}): {appearance}.\n"
                        f"–ü–µ—Ä–µ–¥–∞–π –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ —ç–º–æ—Ü–∏–∏: {emotion_code}.\n"
                        f"–°—Ç–∏–ª—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–∞–∫–∏–º: {style}.\n"
                        "–û—Å—Ç–∞–≤—å –≤–µ—Ä—Ö–Ω—é—é —á–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—É—Å—Ç–æ–π."
                    )
                else:
                    prompt = (
                        f"–ü–æ–≤—Ç–æ—Ä–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ –Ω–æ–≤–æ–π —ç–º–æ—Ü–∏–∏: {emotion_code}.\n"
                        f"–ü—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω.\n"
                        "–û—Å—Ç–∞–≤—å –≤–µ—Ä—Ö–Ω—é—é —á–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—É—Å—Ç–æ–π."
                    )

                print(f"    ‚û°Ô∏è –ê–±–∑–∞—Ü: {para_num} | –≠–º–æ—Ü–∏—è: {emotion_code}")
                image_base64 = None

                response = client.images.generate(
                    model=model,
                    prompt=prompt,
                    n=1,
                    size=size,
                    user=f"book-characters:{int(datetime.now(timezone.utc).timestamp())}"
                )
                image_base64 = response.data[0].b64_json

                if not image_base64:
                    print("‚ùå OpenAI –Ω–µ –≤–µ—Ä–Ω—É–ª base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
                    continue

                # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –û–†–ò–ì–ò–ù–ê–õ –≤ characters/book<id>
                output_file = char_folder / \
                    f"{char_id}_p{para_num}_v{version}_{emotion_code}.webp"
                img_bytes = io.BytesIO()
                img_bytes.write(base64.b64decode(image_base64))
                img_bytes.seek(0)
                with open(output_file, "wb") as f:
                    f.write(img_bytes.read())
                print(f"      üíæ –ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_file}")

                # 2. –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —ç–º–æ—Ü–∏—è p1 ‚Äî –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–º–µ–Ω—å—à–µ–Ω–Ω—É—é –∫–æ–ø–∏—é –≤ ./export/characters
                if para_num == 1 and first_emotion and first_paragraph:
                    chapter_num, para_in_chap = para_map.get(
                        first_paragraph, (None, None))
                    if chapter_num is not None:
                        export_name = f"book_{book_id}_{chapter_num}_{para_in_chap}.webp"
                        export_path = export_dir / export_name
                        # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 512x512:
                        img_bytes.seek(0)
                        img = Image.open(img_bytes)
                        img = img.convert("RGBA")  # –¥–ª—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏
                        img = img.resize((512, 512))
                        img.save(export_path, format="WEBP")
                        img.close()
                        print(f"      üì§ –ö–æ–ø–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {export_path}")

                first_emotion = False

    print("‚úÖ –ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")


def step_comments(book_id, data, paragraphs_with_id, supabase, client):
    print("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–ø–ª–∏–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞.")


def get_characters_appearance(
    book_id: int,
    config_path: str = "config.yaml"
):
    print("üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∫–Ω–∏–≥–∏.")
    supabase = get_supabase_client()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    config = load_config(config_path)
    characters_config = config.get("characters", {})

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
    response = supabase.table("books").select(
        "title, author, text_by_chapters").eq("id", book_id).single().execute()
    if not response.data:
        print("‚ùå –ö–Ω–∏–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    data = response.data
    title = data["title"]
    author = data["author"]
    chapters = json.loads(data["text_by_chapters"])["chapters"]
    print(f"‚úÖ –ö–Ω–∏–≥–∞ –Ω–∞–π–¥–µ–Ω–∞: {title} ({author}). –ì–ª–∞–≤: {len(chapters)}")
    paragraphs_with_id = []
    for chapter in chapters:
        chapter_number = chapter["chapter_number"]
        for idx, paragraph in enumerate(chapter["paragraphs"]):
            paragraphs_with_id.append({
                "chapter": chapter_number,
                "paragraph_idx": idx + 1,
                "text": paragraph
            })
    total_paragraphs = len(paragraphs_with_id)
    print(f"üìù –í—Å–µ–≥–æ –∞–±–∑–∞—Ü–µ–≤: {total_paragraphs}")

    # –≠—Ç–∞–ø—ã –ø–æ –∫–æ–Ω—Ñ–∏–≥—É
    if characters_config.get("find"):
        clean_characters_and_appearance(supabase, book_id)
        step_find_characters_and_appearance(
            book_id, data, paragraphs_with_id, supabase, client)
    if characters_config.get("roles"):
        clean_roles(supabase, book_id)
        step_roles(book_id, data, paragraphs_with_id, supabase, client)
    if characters_config.get("draw"):
        step_draw(book_id, data, paragraphs_with_id, supabase, client)
    if characters_config.get("comments"):
        step_comments(book_id, data, paragraphs_with_id, supabase, client)
