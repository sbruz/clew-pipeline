import os
import re
import time
import json
import spacy
from typing import Optional
from openai import OpenAI, OpenAIError, APIConnectionError, RateLimitError, AuthenticationError
from utils.sentence_splitter import split_into_sentences
from schemas.translation_schema import (
    ChapterParagraphSentence,
    Sentence,
    ChapterItemWithSentences,
    ChapterStructureWithSentences,
    WordItem,
    ParagraphWordAnalysis,
    SentenceOriginal,
    ChapterParagraphSentenceOriginal,
    ChapterParagraphSentenceTranslated,
    ChapterItemWithTranslatedSentences,
    ChapterStructureTranslatedSentences,
)
from schemas.chapter_schema import ChapterStructure
from schemas.paragraph_split import ParagraphParts


def format_text_with_openai(text, lang="en", max_chars=4000) -> str:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    system_prompt = (
        "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é —Ç–µ–∫—Å—Ç–∞. –ü—Ä–∏–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –≤ –ø–æ—Ä—è–¥–æ–∫, –Ω–µ –º–µ–Ω—è—è –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è:\n"
        "- –£–¥–∞–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –∞–±–∑–∞—Ü–µ–≤.\n"
        "- –£–¥–∞–ª–∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π –∞–±–∑–∞—Ü–∞ –∏ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏.\n"
        "- –ó–∞–º–µ–Ω–∏ –¥–≤–æ–π–Ω—ã–µ –∏ —Ç—Ä–æ–π–Ω—ã–µ —Ç–∏—Ä–µ –Ω–∞ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –≤–æ–∫—Ä—É–≥.\n"
        "- –ù–µ –∏–∑–º–µ–Ω—è–π —Ç–µ–∫—Å—Ç, –Ω–µ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
        "- –†–∞–∑–¥–µ–ª—è–π –∞–±–∑–∞—Ü—ã –¥–≤—É–º—è –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ —Å—Ç—Ä–æ–∫–∏.\n"
    )

    try:
        print("‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI...")
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                # <--- –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–∏–º–∏—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
                {"role": "user", "content": text[:max_chars]}
            ],
            temperature=0.2
        )
        print("‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI.")
        return response.choices[0].message.content

    except RateLimitError:
        print("‚õî –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI. –ü–æ–¥–æ–∂–¥–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
    except AuthenticationError:
        print("‚õî –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å OPENAI_API_KEY.")
    except APIConnectionError:
        print("‚õî –ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º. –ü—Ä–æ–≤–µ—Ä—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏–ª–∏ API-–¥–æ—Å—Ç—É–ø.")
    except OpenAIError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {str(e)}")
    except Exception as e:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

    return ""


def run(text, lang, max_chars):
    print("üìò –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
    start = time.time()
    formatted = format_text_with_openai(text, lang, max_chars)
    end = time.time()

    if not formatted:
        print("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å –æ—à–∏–±–∫–∏ –≤—ã—à–µ.")
        return ""

    print(f"‚úÖ –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {round(end - start, 2)} —Å–µ–∫—É–Ω–¥.\n")
    print("üìÑ –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    print(formatted[:1000])
    return formatted


def split_paragraphs_with_openai(text, lang="en", max_chars=4000) -> str:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    system_prompt = (
        "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.\n"
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Ä–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã:\n"
        "- –î–µ–ª–∞–π –∞–±–∑–∞—Ü—ã –¥–æ 150 —Å–∏–º–≤–æ–ª–æ–≤.\n"
        "- –ï—Å–ª–∏ –∞–±–∑–∞—Ü –≤–∫–ª—é—á–∞–µ—Ç –ø—Ä—è–º—É—é —Ä–µ—á—å, –≤—Å—ë —Ä–∞–≤–Ω–æ –º–æ–∂–µ—à—å —Ä–∞–∑–±–∏—Ç—å –µ–≥–æ."
        "- –ê–±–∑–∞—Ü –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
        "- –û—Ç–¥–µ–ª—è–π –∫–∞–∂–¥—ã–π –∞–±–∑–∞—Ü –¥–≤—É–º—è –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫–∏.\n"
        "- –ù–µ –º–µ–Ω—è–π –∏ –Ω–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Ç–µ–∫—Å—Ç.\n"
        "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç."
    )

    try:
        print("‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä–∞–∑–±–∏–≤–∫—É –≤ OpenAI...")
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text[:max_chars]}
            ],
            temperature=0.3
        )
        print("‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI.")
        return response.choices[0].message.content

    except RateLimitError:
        print("‚õî –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI.")
    except AuthenticationError:
        print("‚õî –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å API-–∫–ª—é—á.")
    except APIConnectionError:
        print("‚õî –ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º.")
    except OpenAIError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {str(e)}")
    except Exception as e:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

    return ""


def split_into_paragraphs(book_id, lang, max_chars):
    from utils.supabase_client import get_supabase_client
    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º splitted_text –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        "splitted_text").eq("id", book_id).single().execute()
    text = response.data.get("splitted_text")
    if not text:
        print("‚ùå –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏.")
        return

    result = split_paragraphs_with_openai(text, lang, max_chars)

    if not result:
        print("‚ö†Ô∏è –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –∞–±–∑–∞—Ü—ã –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ.")
        return

    print("üì§ –°–æ—Ö—Ä–∞–Ω—è–µ–º separated_text...")
    supabase.table("books").update(
        {"separated_text": result}).eq("id", book_id).execute()
    print("‚úÖ –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –∞–±–∑–∞—Ü—ã –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")


def group_into_chapters(book_id: int, lang: str, max_chars: int):
    from utils.supabase_client import get_supabase_client
    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º separated_text_verified –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        "separated_text_verified").eq("id", book_id).single().execute()
    text: Optional[str] = response.data.get("separated_text_verified")

    if not text:
        print("‚ùå –¢–µ–∫—Å—Ç –¥–ª—è –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    system_prompt = (
        "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—é —Ç–µ–∫—Å—Ç–∞ –≤ –≥–ª–∞–≤—ã –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.\n"
        "–†–∞–∑–±–µ–π —Ç–µ–∫—Å—Ç –Ω–∞ –≥–ª–∞–≤—ã –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø—Ä–∞–≤–∏–ª–∞–º:\n"
        "- –ù–æ–≤–∞—è –≥–ª–∞–≤–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ç–∞–º, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–æ–≤–∞—è —Å—Ü–µ–Ω–∞ –∏–ª–∏ –≤–Ω–∏–º–∞–Ω–∏–µ —á–∏—Ç–∞—Ç–µ–ª—è –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ.\n"
        "- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≥–ª–∞–≤—ã: –æ—Ç 15 –¥–æ 50 –∞–±–∑–∞—Ü–µ–≤.\n"
        "- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî —Å–º—ã—Å–ª–æ–≤–æ–µ –¥–µ–ª–µ–Ω–∏–µ, –∞ –Ω–µ –¥–ª–∏–Ω–∞.\n"
        "- –ù–µ –∏–∑–º–µ–Ω—è–π —Ç–µ–∫—Å—Ç –∞–±–∑–∞—Ü–µ–≤.\n"
        "- –ù–∞—á–∏–Ω–∞–π –Ω—É–º–µ—Ä–∞—Ü–∏—é –∞–∑–±–∞—Ü–µ–≤ —Å 1 –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –≥–ª–∞–≤—ã.\n"
        "- –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ JSON, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –æ–∂–∏–¥–∞–µ–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.\n"
    )

    try:
        print("‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ GPT –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ –≥–ª–∞–≤—ã...")

        completion = client.beta.chat.completions.parse(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text[:max_chars]}
            ],
            response_format=ChapterStructure,
        )

        chapter_data = completion.choices[0].message.parsed

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É JSON –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Supabase
        json_text = chapter_data.model_dump_json(indent=2)

        supabase.table("books").update(
            {"text_by_chapters": json_text}).eq("id", book_id).execute()
        print("‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ –≥–ª–∞–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–∏–≤–∫–µ –Ω–∞ –≥–ª–∞–≤—ã: {e}")


def simplify_text_for_beginners(book_id: int, lang: str, max_chars: int):
    from utils.supabase_client import get_supabase_client
    from schemas.chapter_schema import ChapterStructure, ChapterItem
    import json

    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º text_by_chapters –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        "text_by_chapters").eq("id", book_id).single().execute()
    original_text = response.data.get("text_by_chapters")

    if not original_text:
        print("‚ùå –ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏.")
        return

    original_structure = ChapterStructure.model_validate_json(original_text)
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    lang_map = {
        "en": "–∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
        "es": "–∏—Å–ø–∞–Ω—Å–∫–æ–º",
        "fr": "—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º",
        "de": "–Ω–µ–º–µ—Ü–∫–æ–º"
    }

    # –µ—Å–ª–∏ —è–∑—ã–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –æ–±–æ–±—â—ë–Ω–Ω–æ
    selected_lang = lang_map.get(lang, "–∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–º")

    system_prompt = (
        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä–∞—Å—Å–∫–∞–∑—á–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–ª–∞–≤—ã –∫–Ω–∏–≥ –¥–ª—è –∏–∑—É—á–∞—é—â–∏—Ö –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.\n"
        "–ü—Ä–∞–≤–∏–ª–∞:\n"
        "- –ü–µ—Ä–µ–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ—Ä–æ—Ç–∫–∏–µ, –ª—ë–≥–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—É—Ä–æ–≤–µ–Ω—å A2‚ÄìB1).\n"
        "- –°–æ—Ö—Ä–∞–Ω—è–π —Ä–∞–∑–±–∏–≤–∫—É –Ω–∞ –∞–±–∑–∞—Ü—ã ‚Äî –Ω–µ –æ–±—ä–µ–¥–∏–Ω—è–π –∏ –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–π –∞–±–∑–∞—Ü—ã.\n"
        f"- –ü–∏—à–∏ –Ω–∞ {selected_lang} —è–∑—ã–∫–µ.\n"
        "- –ü–∏—à–∏ –≤ —Ç—ë–ø–ª–æ–º, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–º —Ç–æ–Ω–µ ‚Äî –∫–∞–∫ –±—É–¥—Ç–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—à—å –∏—Å—Ç–æ—Ä–∏—é –¥—Ä—É–≥—É.\n"
        "- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –¥–ª–∏–Ω–Ω—ã—Ö –∏–ª–∏ —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π. –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω–æ —Å–∞–º–æ –ø–æ —Å–µ–±–µ.\n"
        "- –ù–µ –ø–∏—à–∏ –∫–∞–∫ —É—á–µ–±–Ω–∏–∫. –ü–∏—à–∏ –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π —Ö–æ—Ä–æ—à–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç.\n"
        "- –ù–µ —É–ø—Ä–æ—â–∞–π –¥–æ —É—Ä–æ–≤–Ω—è —Ä–æ–±–æ—Ç–∞ ‚Äî —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω '—Ç–µ—á—å' –∂–∏–≤–æ, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –ø–æ–Ω—è—Ç–Ω–æ.\n"
        "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –≥–ª–∞–≤—ã –ø–æ —Å—Ö–µ–º–µ ChapterItem. –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
    )

    simplified_chapters = []

    total_chapters = len(original_structure.chapters)

    for idx, chapter in enumerate(original_structure.chapters, start=1):
        progress = round((idx / total_chapters) * 100)
        print(
            f"\nüìò –ì–ª–∞–≤–∞ {chapter.chapter_number} ‚Äî {len(chapter.paragraphs)} –∞–±–∑–∞—Ü–µ–≤ ({progress}%)")

        chapter_attempts = 0
        success = False

        while chapter_attempts < 3 and not success:
            chapter_attempts += 1
            print(f"  üîÑ –ü–æ–ø—ã—Ç–∫–∞ {chapter_attempts}...")

            try:
                chapter_json = chapter.model_dump_json(indent=2)

                completion = client.beta.chat.completions.parse(
                    model="gpt-4.1",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": chapter_json[:max_chars]}
                    ],
                    response_format=ChapterItem,
                )

                simplified = completion.choices[0].message.parsed

                original_count = len(chapter.paragraphs)
                simplified_count = len(simplified.paragraphs)

                if simplified_count != original_count:
                    print(
                        f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: –æ–∂–∏–¥–∞–ª–æ—Å—å {original_count} –∞–±–∑–∞—Ü–µ–≤, –ø–æ–ª—É—á–µ–Ω–æ {simplified_count}")
                else:
                    print(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ. –ê–±–∑–∞—Ü–µ–≤: {simplified_count}")
                    simplified_chapters.append(simplified)
                    success = True

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ GPT: {e}")

        if not success:
            print(
                f"‚õî –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –≥–ª–∞–≤—ã {chapter.chapter_number}. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
            return

    # –°–±–æ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    final_structure = ChapterStructure(chapters=simplified_chapters)
    json_text = final_structure.model_dump_json(indent=2)

    supabase.table("books").update(
        {"text_by_chapters_simplified": json_text}).eq("id", book_id).execute()
    print("\n‚úÖ –í—Å–µ –≥–ª–∞–≤—ã –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")


def translate_text_structure(
    book_id: int,
    source_field: str,
    result_field: str,
    source_lang: str,
    target_lang: str,
    max_chars: int
):
    from utils.supabase_client import get_supabase_client
    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º {source_field} –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        source_field).eq("id", book_id).single().execute()
    text = response.data.get(source_field)

    if not text:
        print(f"‚ùå –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –≤ –ø–æ–ª–µ {source_field}.")
        return

    original_structure = ChapterStructure.model_validate_json(text)
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    paragraphs_sentences_flat = []
    chapters_result = []

    total_paragraphs = sum(len(ch.paragraphs)
                           for ch in original_structure.chapters)
    translated_count = 0

    system_prompt_translate = (
        f"–ü–µ—Ä–µ–≤–µ–¥–∏ –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å {source_lang} –Ω–∞ {target_lang}. "
        "–°—Ç—Ä—É–∫—Ç—É—Ä—É JSON –Ω–µ –º–µ–Ω—è–π: –¥–æ–±–∞–≤—å –ø–æ–ª–µ 'sentence_translation' —Ä—è–¥–æ–º —Å 'sentence_original'. "
        "–ù–µ —É–¥–∞–ª—è–π, –Ω–µ –æ–±—ä–µ–¥–∏–Ω—è–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü–µ—Ä–µ–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º."
    )

    for chapter in original_structure.chapters:
        print(f"\nüìö –ì–ª–∞–≤–∞ {chapter.chapter_number}")
        translated_paragraphs = []

        for paragraph in chapter.paragraphs:
            print(f"  ‚úÇÔ∏è –ê–±–∑–∞—Ü {paragraph.paragraph_number}")

            raw_sentences = split_into_sentences(
                paragraph.paragraph_content, source_lang)
            para_struct_original = ChapterParagraphSentenceOriginal(
                paragraph_number=paragraph.paragraph_number,
                sentences=[
                    SentenceOriginal(
                        sentence_number=i + 1,
                        sentence_original=s.strip()
                    )
                    for i, s in enumerate(raw_sentences)
                ]
            )
            paragraphs_sentences_flat.append(para_struct_original)

            # –ü–µ—Ä–µ–≤–æ–¥
            attempt = 0
            success = False

            while attempt < 3 and not success:
                attempt += 1
                try:
                    print(f"    üåç –ü–µ—Ä–µ–≤–æ–¥ (–ø–æ–ø—ã—Ç–∫–∞ {attempt})...")
                    completion = client.beta.chat.completions.parse(
                        model="gpt-4.1",
                        messages=[
                            {"role": "system", "content": system_prompt_translate},
                            {"role": "user", "content": para_struct_original.model_dump_json(indent=2)[
                                :max_chars]}
                        ],
                        response_format=ChapterParagraphSentenceTranslated
                    )
                    translated_para = completion.choices[0].message.parsed

                    if len(translated_para.sentences) != len(para_struct_original.sentences):
                        print(
                            f"    ‚ö†Ô∏è –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {len(para_struct_original.sentences)} ‚Üí {len(translated_para.sentences)}")
                    else:
                        translated_paragraphs.append(translated_para)
                        translated_count += 1
                        percent = round(
                            (translated_count / total_paragraphs) * 100)
                        print(
                            f"    ‚úÖ –£—Å–ø–µ—à–Ω–æ. üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {translated_count}/{total_paragraphs} ({percent}%)")
                        success = True

                except Exception as e:
                    print(f"    ‚ùå –û—à–∏–±–∫–∞ GPT: {e}")
                    time.sleep(2)

            if not success:
                print(
                    f"‚õî –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –∞–±–∑–∞—Ü {paragraph.paragraph_number}. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                return

        chapters_result.append(ChapterItemWithTranslatedSentences(
            chapter_number=chapter.chapter_number,
            paragraphs=translated_paragraphs
        ))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (SentenceTranslated)
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º {result_field}...")
    full_structure = ChapterStructureTranslatedSentences(
        chapters=chapters_result)
    json_translated = full_structure.model_dump_json(indent=2)
    supabase.table("books").update(
        {result_field: json_translated}).eq("id", book_id).execute()

    print("\n‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –≤—Å–µ—Ö –∞–±–∑–∞—Ü–µ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω.")


def enrich_sentences_with_words(
    book_id: int,
    source_field: str,
    result_field: str,
    source_lang: str,
    target_lang: str,
    max_chars: int
):
    from utils.supabase_client import get_supabase_client
    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º {source_field} –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        source_field).eq("id", book_id).single().execute()
    text = response.data.get(source_field)

    if not text:
        print(f"‚ùå –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –≤ –ø–æ–ª–µ {source_field}.")
        return

    structure = ChapterStructureWithSentences.model_validate_json(text)
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    total_sentences = sum(len(p.sentences)
                          for c in structure.chapters for p in c.paragraphs)
    enriched_count = 0

    system_prompt = (
        f"–¢—ã ‚Äî —è–∑—ã–∫–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫.\n"
        f"–û—á–∏—Å—Ç–∏ –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ —Ä–∞–∑–±–µ–π –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–æ –¥–ª–∏–Ω–µ —Å–º—ã—Å–ª–æ–≤—ã–µ –≥—Ä—É–ø–ø—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–º–µ—Å—Ç–µ —Ñ—Ä–∞–∑–æ–≤—ã–µ –≥–ª–∞–≥–æ–ª—ã, –∏–¥–∏–æ–º—ã.\n"
        f"–î–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —É–∫–∞–∂–∏:\n"
        f"- o: –æ—Ä–∏–≥–∏–Ω–∞–ª\n"
        f"- o_t: –ø–µ—Ä–µ–≤–æ–¥\n"
        f"- l: –ª–µ–º–º–∞ (–µ—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å o, –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º)\n"
        f"- l_t: –ø–µ—Ä–µ–≤–æ–¥ –ª–µ–º–º—ã (–µ—Å–ª–∏ l –ø—É—Å—Ç–æ–µ, –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º)\n\n"
        f"–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (response_format)."
    )

    for chapter in structure.chapters:
        print(f"\nüìö –ì–ª–∞–≤–∞ {chapter.chapter_number}")

        for paragraph in chapter.paragraphs:
            print(
                f"  ‚úÇÔ∏è –ê–±–∑–∞—Ü {paragraph.paragraph_number} ‚Äî {len(paragraph.sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

            attempt = 0
            success = False

            while attempt < 3 and not success:
                attempt += 1
                try:
                    input_data = [
                        {
                            "sentence_number": s.sentence_number,
                            "sentence_original": s.sentence_original,
                            "sentence_translation": s.sentence_translation
                        }
                        for s in paragraph.sentences
                    ]

                    completion = client.beta.chat.completions.parse(
                        model="gpt-4.1",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": json.dumps(
                                input_data, ensure_ascii=False, indent=2)[:max_chars]}
                        ],
                        response_format=ParagraphWordAnalysis,
                    )

                    parsed_paragraph = completion.choices[0].message.parsed
                    parsed_sentences = parsed_paragraph.sentences

                    if len(parsed_sentences) != len(paragraph.sentences):
                        print(
                            f"    ‚ö†Ô∏è –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —á–∏—Å–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: –æ–∂–∏–¥–∞–ª–æ—Å—å {len(paragraph.sentences)}, –ø–æ–ª—É—á–µ–Ω–æ {len(parsed_sentences)}")
                    else:
                        for sentence in paragraph.sentences:
                            match = next(
                                (s for s in parsed_sentences if s.sentence_number == sentence.sentence_number), None)
                            if not match:
                                raise ValueError(
                                    f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence.sentence_number} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                            sentence.words = match.words

                        enriched_count += len(paragraph.sentences)
                        percent = round(
                            (enriched_count / total_sentences) * 100)
                        print(
                            f"    ‚úÖ –£—Å–ø–µ—à–Ω–æ ‚Äî {len(paragraph.sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {enriched_count}/{total_sentences} ({percent}%)")
                        success = True

                except Exception as e:
                    print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–ª–æ–≤: {e}")

            if not success:
                print(
                    f"‚õî –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞–±–∑–∞—Ü {paragraph.paragraph_number}. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                return

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º {result_field}...")
    json_result = structure.model_dump_json(indent=2)
    supabase.table("books").update(
        {result_field: json_result}).eq("id", book_id).execute()

    print("‚úÖ –†–∞–∑–±–æ—Ä —Å–ª–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")

# –Ω–æ–≤—ã–π –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —à–∞–≥ –ø–æ—Å–ª–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è


def split_into_sentences(book_id, lang="en", max_chars=4000):
    from utils.supabase_client import get_supabase_client

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º formated_text –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        "formated_text").eq("id", book_id).single().execute()
    text = response.data.get("formated_text")
    if not text:
        print("‚ùå –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏.")
        return

    system_prompt = (
        "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.\n"
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Ä–∞–∑–±–∏—Ç—å –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –ª–æ–≥–∏—á–µ—Å–∫—É—é –∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å.\n"
        "- –û—Å—Ç–∞–≤—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏ —Ä–∞–∑–±–∏–≤–∫–µ –º–æ–≥—É—Ç –ø–æ—Ç–µ—Ä—è—Ç—å —Å–º—ã—Å–ª.\n"
        "- –ù–µ –∏–∑–º–µ–Ω—è–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –∏ –Ω–µ –∏–∑–º–µ–Ω—è–π —Ç–µ–∫—Å—Ç.\n"
        "- –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤–∫–ª—é—á–∞–µ—Ç –ø—Ä—è–º—É—é —Ä–µ—á—å, –≤—Å—ë —Ä–∞–≤–Ω–æ –º–æ–∂–µ—à—å —Ä–∞–∑–±–∏—Ç—å –µ—ë –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –µ—Å–ª–∏ —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫—É—é –∏ –ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å. –ù–µ –±–æ–π—Å—è —Å—Ç–∞–≤–∏—Ç—å —Ç–æ—á–∫–∏ –¥–∞–∂–µ –≤–Ω—É—Ç—Ä–∏ –∫–∞–≤—ã—á–µ–∫. –í—Å—Ç–∞–≤–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ –∑–∞–ø—è—Ç—ã–º–∏ ‚Äî –Ω–µ –ø–æ–≤–æ–¥ –∏–∑–±–µ–≥–∞—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏—è. –ü—Ä–æ—Å—Ç–æ —Å–æ–±–ª—é–¥–∞–π —Å–º—ã—Å–ª."
        "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç."
    )

    try:
        print("‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä–∞–∑–±–∏–≤–∫—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ OpenAI...")
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text[:max_chars]}
            ],
            temperature=0.3
        )
        print("‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI.")
        result = response.choices[0].message.content

    except RateLimitError:
        print("‚õî –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI.")
        return
    except AuthenticationError:
        print("‚õî –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å API-–∫–ª—é—á.")
        return
    except APIConnectionError:
        print("‚õî –ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º.")
        return
    except OpenAIError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {str(e)}")
        return
    except Exception as e:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        return

    if not result:
        print("‚ö†Ô∏è –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ.")
        return

    print("üì§ –°–æ—Ö—Ä–∞–Ω—è–µ–º splitted_text...")
    supabase.table("books").update(
        {"splitted_text": result}).eq("id", book_id).execute()
    print("‚úÖ –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")

# –†–£–ß–ù–ê–Ø –†–ê–ó–ë–ò–í–ö–ê –¢–ï–ö–°–¢–ê –ù–ê –ü–ê–†–ê–ì–†–ê–§–´


def split_paragraph_manually(paragraph: str, spacy_nlp, max_length: int = 200, min_chunk_len: int = 30) -> list[str]:
    doc = spacy_nlp(paragraph)
    sentences = [sent.text.strip() for sent in doc.sents]

    new_paragraphs = []
    current = ""

    for i, sentence in enumerate(sentences):
        # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Å–∏–º–≤–æ–ª–æ–≤ –æ—Å—Ç–∞–ª–æ—Å—å –≤ –∞–±–∑–∞—Ü–µ, –µ—Å–ª–∏ –±—ã –º—ã –ù–ï –¥–æ–±–∞–≤–∏–ª–∏ —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        remaining_sentences = sentences[i:]
        remaining_length = sum(len(s) for s in remaining_sentences)

        # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        if len(current) < min_chunk_len:
            current += (" " if current else "") + sentence
            continue

        # –ù–µ –æ—Ç–¥–µ–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ —Ö–≤–æ—Å—Ç
        if remaining_length < min_chunk_len:
            current += (" " if current else "") + sentence
            continue

        # –ï—Å–ª–∏ –º–æ–∂–µ–º –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—è –ª–∏–º–∏—Ç ‚Äî –¥–æ–±–∞–≤–∏–º
        if len(current) + len(sentence) + 1 <= max_length:
            current += (" " if current else "") + sentence
        else:
            # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –∞–±–∑–∞—Ü
            if current:
                new_paragraphs.append(current.strip())
            current = sentence

    if current:
        new_paragraphs.append(current.strip())

    return new_paragraphs


def verify_separated_text(book_id: int, lang_code: str, nlp):
    from utils.supabase_client import get_supabase_client
    supabase = get_supabase_client()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º separated_text –¥–ª—è –∫–Ω–∏–≥–∏ {book_id}...")
    response = supabase.table("books").select(
        "separated_text").eq("id", book_id).single().execute()
    text: Optional[str] = response.data.get("separated_text")

    if not text:
        print("‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    end_punctuation = re.compile(r"[.!?‚Ä¶]")
    paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
    long_paragraphs = [p for p in paragraphs if len(p) > 200]

    print(
        f"üîç –í—Å–µ–≥–æ –∞–±–∑–∞—Ü–µ–≤: {len(paragraphs)} | –î–ª–∏–Ω–Ω—ã—Ö: {len(long_paragraphs)}")

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    verified_paragraphs = []
    progress_log = []

    for idx, paragraph in enumerate(paragraphs, start=1):
        if len(paragraph) <= 200:
            verified_paragraphs.append(paragraph)
            continue

        status = "failed"
        if end_punctuation.search(paragraph):
            try:
                chunk_count = max(1, round(len(paragraph) / 150))
                system_prompt = (
                    f"–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –¥–µ–ª–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞. –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ ‚Äî {lang_code}. "
                    f"–†–∞–∑–¥–µ–ª–∏ –∞–±–∑–∞—Ü –Ω–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω—ã–µ —á–∞—Å—Ç–∏ –ø–æ –¥–ª–∏–Ω–µ, —Ç–∞–∫, —á—Ç–æ–±—ã –∫–∞–∂–¥–∞—è —á–∞—Å—Ç—å –∑–∞–∫–∞–Ω—á–∏–≤–∞–ª–∞—Å—å –ø–æ–ª–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º. "
                    f"–¶–µ–ª—å ‚Äî —Ä–∞–∑–±–∏—Ç—å –∞–±–∑–∞—Ü –Ω–∞ {chunk_count} —á–∞—Å—Ç–µ–π. –ù–µ –∏–∑–º–µ–Ω—è–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ. "
                    "–û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –≤ JSON: {\"parts\": [\"—á–∞—Å—Ç—å 1\", \"—á–∞—Å—Ç—å 2\", ...]}"
                )

                completion = client.beta.chat.completions.parse(
                    model="gpt-4.1",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": paragraph}
                    ],
                    response_format=ParagraphParts
                )

                parts = completion.choices[0].message.parsed.parts
                all_good = True

                for part in parts:
                    if len(part) > 200 and end_punctuation.search(part):
                        manual_parts = split_paragraph_manually(part, nlp)
                        verified_paragraphs.extend(manual_parts)
                        if any(len(p) > 200 for p in manual_parts):
                            status = "failed"
                        else:
                            status = "manual OK"
                        all_good = False
                    else:
                        verified_paragraphs.append(part)

                if all_good:
                    status = "openai OK"

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ GPT: {e}. –ü—Ä–æ–±—É–µ–º –≤—Ä—É—á–Ω—É—é...")
                manual_parts = split_paragraph_manually(paragraph, nlp)
                verified_paragraphs.extend(manual_parts)
                if any(len(p) > 200 for p in manual_parts):
                    status = "failed"
                else:
                    status = "manual OK"
        else:
            verified_paragraphs.append(paragraph)
            status = "failed"

        if len(paragraph) > 200:
            log_index = len(progress_log) + 1
            print(
                f"üß© –î–ª–∏–Ω–Ω—ã–π –∞–±–∑–∞—Ü {log_index}/{len(long_paragraphs)} ‚Üí {status}")
            progress_log.append((log_index, status))

    final_text = "\n\n".join(verified_paragraphs)
    supabase.table("books").update(
        {"separated_text_verified": final_text}
    ).eq("id", book_id).execute()

    print("üì§ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ separated_text_verified.")
