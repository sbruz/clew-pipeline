import os
import json
import base64
import yaml
from pathlib import Path
from openai import OpenAI
from utils.supabase_client import get_supabase_client
from schemas.pictures import BookObject, BookObjectsResponse
from PIL import Image
import numpy as np
import io


def load_config(config_path: str = "config.yaml") -> dict:
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def enhance_highlights_and_shadows(image_bytes):
    # –û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –±–∞–π—Ç–æ–≤
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    arr = np.array(image).astype(np.float32) / 255.0

    # –ö—Ä—É—Ç–∞—è S-–∫—Ä–∏–≤–∞—è: —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç
    def contrast_boost(x):
        return np.clip((x - 0.5) * 4 + 0.5, 0, 1)
    arr_boosted = contrast_boost(arr)
    arr_boosted = (arr_boosted * 255).astype(np.uint8)
    result_image = Image.fromarray(arr_boosted, mode="RGB")
    # –†–µ—Å–∞–π–∑ –¥–æ 512x512
    result_image = result_image.resize((512, 512), Image.LANCZOS)

    return result_image


def get_image_score_via_openai(client, eval_prompt, pil_image):
    import base64
    import io
    buffered = io.BytesIO()
    pil_image.save(buffered, format="WEBP")
    image_bytes = buffered.getvalue()
    image_base64 = base64.b64encode(image_bytes).decode("utf-8")
    messages = [
        {"role": "system", "content": "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è–º –∫–Ω–∏–≥ –∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É."},
        {"role": "user", "content": [
            {"type": "text", "text": eval_prompt},
            {"type": "image_url", "image_url": {
                "url": f"data:image/webp;base64,{image_base64}"}}
        ]}
    ]
    response = client.chat.completions.create(
        model="gpt-4o",  # –í–∞–∂–Ω–æ: vision –º–æ–¥–µ–ª—å!
        messages=messages,
        max_tokens=4
    )
    try:
        score = int(response.choices[0].message.content.strip())
    except Exception:
        score = 1
    return score


def generate_object_pictures_for_book(
    book_id: int,
    config_path: str = "config.yaml"
):
    import base64
    import io
    from pathlib import Path

    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π –¥–ª—è –∫–Ω–∏–≥–∏.")
    supabase = get_supabase_client()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    config = load_config(config_path)

    # 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –∫–Ω–∏–≥–µ
    print(f"üìö –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏ (book_id={book_id}) ...")
    response = supabase.table("books").select(
        "title, author, text_by_chapters"
    ).eq("id", book_id).single().execute()
    if not response.data:
        print("‚ùå –ö–Ω–∏–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    data = response.data
    title = data["title"]
    author = data["author"]
    chapters = json.loads(data["text_by_chapters"])["chapters"]
    print(f"‚úÖ –ö–Ω–∏–≥–∞ –Ω–∞–π–¥–µ–Ω–∞: {title} ({author}). –ì–ª–∞–≤: {len(chapters)}")

    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∞–±–∑–∞—Ü–µ–≤ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º id
    paragraphs_with_id = []
    total_paragraphs = 0
    for chapter in chapters:
        chapter_number = chapter["chapter_number"]
        if chapter_number > 2:
            continue
        for idx, paragraph in enumerate(chapter["paragraphs"]):
            para_id = f"book_{book_id}_{chapter_number}_{idx+1}"
            paragraphs_with_id.append({
                "id": para_id,
                "text": paragraph
            })
            total_paragraphs += 1
    print(f"üìù –í—Å–µ–≥–æ –∞–±–∑–∞—Ü–µ–≤: {total_paragraphs}")

    # 3. –ó–∞–ø—Ä–æ—Å –≤ OpenAI –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    print("ü§ñ –ó–∞–ø—Ä–æ—Å –∫ OpenAI: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –¥–ª—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ ...")
    book_text = "\n\n".join(
        [f"[{p['id']}]\n{p['text']}" for p in paragraphs_with_id]
    )
    system_prompt = (
        "–¢—ã ‚Äî –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–æ–≤–µ–¥ –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–º—É —Å—Ç–æ—Ä–∏—Ç–µ–ª–ª–∏–Ω–≥—É.\n"
        f"–ü–µ—Ä–µ–¥ —Ç–æ–±–æ–π —Ç–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ '{title}' –∞–≤—Ç–æ—Ä–∞ {author}, —Ä–∞–∑–±–∏—Ç—ã–π –Ω–∞ –∞–±–∑–∞—Ü—ã —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏.\n"
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∞–±–∑–∞—Ü—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ —Ç–µ, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ø–µ—Ä–≤—ã–π —Ä–∞–∑ –ø–æ—è–≤–ª—è—é—Ç—Å—è —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ —Å—é–∂–µ—Ç–∞ –ø—Ä–µ–¥–º–µ—Ç—ã –∏–ª–∏ –æ–±—ä–µ–∫—Ç—ã.\n"
        "–ù–µ —É—á–∏—Ç—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç—ã, –æ –∫–æ—Ç–æ—Ä—ã—Ö –≥–æ–≤–æ—Ä—è—Ç, –Ω–æ –∏—Ö –Ω–µ—Ç –≤ –∫–∞–¥—Ä–µ.\n"
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–∫–æ–≥–æ –∞–±–∑–∞—Ü–∞ –¥–∞–π —Ç–∞–∫–æ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞ –∏–ª–∏ –æ–±—ä–µ–∫—Ç–∞, –∫–∞–∫ –∑–∞–¥–∞–Ω–∏–µ –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏, —á—Ç–æ–±—ã –µ–≥–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å —Å–æ–≥–ª–∞—Å–Ω–æ —Å—é–∂–µ—Ç–∞ –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã –∫–Ω–∏–≥–∏. –ù–µ –ø–∏—à–∏ –∏–º–µ–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–º–µ—Ç—ã –∏ –æ–±—ä–µ–∫—Ç—ã.\n"
        "–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ —ç–∫–∑–µ–º–ø–ª—è—Ä BookObjectsResponse, –≤ –∫–æ—Ç–æ—Ä–æ–º objects ‚Äî —ç—Ç–æ –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ BookObject.\n"
        "BookObject: {\"paragraph_id\": ..., \"object_description\": ...}"
    )

    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": book_text[:100000]}
            ],
            response_format=BookObjectsResponse
        )
        result = completion.choices[0].message.parsed
        object_list = result.objects
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(object_list)} –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π.")
        for i, obj in enumerate(object_list, 1):
            print(f"   {i}. [{obj.paragraph_id}] {obj.object_description}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–Ω–∏–≥–∏: {e}")
        return

    # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
    output_dir = Path(f"export/pictures/book_{book_id}")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"üìÇ –ü–∞–ø–∫–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {output_dir.resolve()}")

    # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ (—á–µ—Ä–Ω—ã–π –∏ –±–µ–ª—ã–π —Ñ–æ–Ω)
    total_tasks = len(object_list) * 2
    task_count = 0
    print(f"üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {total_tasks} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ...")
    for obj_idx, obj in enumerate(object_list, 1):
        for bg in ["b", "w"]:  # b=black, w=white
            task_count += 1
            prompt_bg = config["styles"]["prompt_black_bg"] if bg == "b" else config["styles"]["prompt_white_bg"]

            prompt = (
                f"Style: {prompt_bg}\n"
                f"Object: {obj.object_description}. Draw only it.\n"
                f"Book: '{title}', author: {author}. Use it to draw according to the genre and period of time.\n"
                f"Focus on the main object and leave background clean. "
            )
            bg_label = "—á—ë—Ä–Ω—ã–π" if bg == "b" else "–±–µ–ª—ã–π"
            print(
                f"[{task_count}/{total_tasks}] üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: [{obj.paragraph_id}] '{obj.object_description}', —Ñ–æ–Ω: {bg_label}")

            try:
                # === –ü–µ—Ä–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ===
                response = client.images.generate(
                    model="gpt-image-1",
                    prompt=prompt,
                    n=1,
                    size="1024x1024"
                )
                image_base64_1 = response.data[0].b64_json
                if not image_base64_1:
                    print(
                        f"   ‚ùå –ù–µ—Ç base64 –¥–ª—è [{obj.paragraph_id}] ({bg_label})")
                    continue

                # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç–∏ –∏ resize ---
                image_bytes_1 = base64.b64decode(image_base64_1)
                enhanced_image_1 = enhance_highlights_and_shadows(
                    image_bytes_1)

                # --- –û—Ü–µ–Ω–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è OpenAI ---
                print(
                    "   üìù –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—é —á–µ—Ä–µ–∑ OpenAI ...")
                eval_prompt = (
                    f"–û—Ü–µ–Ω–∏ –ø–æ 10-–±–∞–ª–ª—å–Ω–æ–π —à–∫–∞–ª–µ, –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–æ–∫, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é –ø—Ä–µ–¥–º–µ—Ç–∞.\n"
                    f"–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–∞: {obj.object_description}\n"
                    f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 10 –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
                )
                score_1 = get_image_score_via_openai(
                    client, eval_prompt, enhanced_image_1)
                print(f"   üîé –û—Ü–µ–Ω–∫–∞ OpenAI: {score_1}/10")

                # –ï—Å–ª–∏ –æ—Ü–µ–Ω–∫–∞ >=7 ‚Äî —Å—Ä–∞–∑—É —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                if score_1 >= 7:
                    file_path = output_dir / f"{obj.paragraph_id}_{bg}.webp"
                    enhanced_image_1.save(file_path, format="WEBP")
                    print(
                        f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {file_path.name} (–æ—Ü–µ–Ω–∫–∞ {score_1}/10)")
                    continue

                # === –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ===
                print("   ‚Ü©Ô∏è –û—Ü–µ–Ω–∫–∞ –Ω–∏–∂–µ 7, –ø–æ–≤—Ç–æ—Ä—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é ...")
                response2 = client.images.generate(
                    model="gpt-image-1",
                    prompt=prompt,
                    n=1,
                    size="1024x1024"
                )
                image_base64_2 = response2.data[0].b64_json
                if not image_base64_2:
                    print(
                        f"   ‚ùå –ù–µ—Ç base64 (2) –¥–ª—è [{obj.paragraph_id}] ({bg_label})")
                    file_path = output_dir / f"{obj.paragraph_id}_{bg}.webp"
                    enhanced_image_1.save(file_path, format="WEBP")
                    print(
                        f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ (–ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ): {file_path.name}")
                    continue

                image_bytes_2 = base64.b64decode(image_base64_2)
                enhanced_image_2 = enhance_highlights_and_shadows(
                    image_bytes_2)
                score_2 = get_image_score_via_openai(
                    client, eval_prompt, enhanced_image_2)
                print(f"   üîé –û—Ü–µ–Ω–∫–∞ OpenAI (2): {score_2}/10")

                # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                if score_2 > score_1:
                    file_path = output_dir / f"{obj.paragraph_id}_{bg}.webp"
                    enhanced_image_2.save(file_path, format="WEBP")
                    print(
                        f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {file_path.name} (–æ—Ü–µ–Ω–∫–∞ {score_2}/10)")
                else:
                    file_path = output_dir / f"{obj.paragraph_id}_{bg}.webp"
                    enhanced_image_1.save(file_path, format="WEBP")
                    print(
                        f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ (–ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ): {file_path.name} (–æ—Ü–µ–Ω–∫–∞ {score_1}/10)")

            except Exception as e:
                print(
                    f"   ‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è [{obj.paragraph_id}] ({bg_label}): {e}")

    print(f"üèÅ –ì–æ—Ç–æ–≤–æ! –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {task_count} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–Ω–∏–≥–∏ '{title}'.")
