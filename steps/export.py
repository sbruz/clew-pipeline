import os
import json
from pathlib import Path
from utils.supabase_client import get_supabase_client
from schemas.export_schema import LocalizedMeta
from openai import OpenAI


import os
import json
from pathlib import Path
from utils.supabase_client import get_supabase_client
from openai import OpenAI
from pydantic import BaseModel


class LocalizedMeta(BaseModel):
    localized_title: str
    localized_author: str


def fetch_localized_title_and_author(title: str, author: str, year: str, target_lang: str) -> LocalizedMeta:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    lang_map = {
        "en": "–∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
        "es": "–∏—Å–ø–∞–Ω—Å–∫–æ–º",
        "fr": "—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º",
        "de": "–Ω–µ–º–µ—Ü–∫–æ–º",
        "it": "–∏—Ç–∞–ª—å—è–Ω—Å–∫–æ–º",
        "ru": "—Ä—É—Å—Å–∫–æ–º"
    }

    # –µ—Å–ª–∏ —è–∑—ã–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –æ–±–æ–±—â—ë–Ω–Ω–æ
    selected_lang = lang_map.get(target_lang, "–∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–º")

    system_prompt = (
        f"–í–µ—Ä–Ω–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ '{title}', {author}, {year}, –ø–æ–¥ –∫–æ—Ç–æ—Ä—ã–º –æ–Ω–∞ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞—Å—å —Ä–∞–Ω–µ–µ –Ω–∞ {selected_lang} —è–∑—ã–∫–µ.\n"
        f"–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ–±—ã —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –±—ã–ª–æ –Ω–µ –æ—Ç –¥—Ä—É–≥–æ–≥–æ –ø–æ—Ö–æ–∂–µ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞.\n"
        f"–ï—Å–ª–∏ —É —Ç–µ–±—è –Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äì¬†–¥–∞–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, –∫–∞–∫ –±—ã —Å–∫–∞–∑–∞–ª–∏ –Ω–æ—Å–∏—Ç–µ–ª–∏ –Ω–∞ {selected_lang} —è–∑—ã–∫–µ.\n"
        f"–¢–∞–∫–∂–µ –¥–∞–π –∏–º—è –∞–≤—Ç–æ—Ä–∞ –Ω–∞ {selected_lang} —è–∑—ã–∫–µ, –µ—Å–ª–∏ –æ–Ω–æ –∏–º–µ–µ—Ç –æ–±—â–µ–ø—Ä–∏–Ω—è—Ç—ã–π –ø–µ—Ä–µ–≤–æ–¥.\n"
        f"–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON-–æ–±—ä–µ–∫—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å—Ö–µ–º–æ–π."
    )

    completion = client.beta.chat.completions.parse(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"title: {title}\nauthor: {author}\nyear: {year}"}
        ],
        response_format=LocalizedMeta,
    )

    return completion.choices[0].message.parsed


def export_book_json(book_id: int, source_lang: str, target_lang: str):
    supabase = get_supabase_client()

    # üì¶ –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –∫–Ω–∏–≥
    if book_id == -1:
        response = supabase.table("books").select("id").execute()
        ids = [item["id"] for item in response.data]
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥: {len(ids)}")
        for i in ids:
            export_book_json(i, source_lang, target_lang)
        return

    print(f"üì¶ –≠–∫—Å–ø–æ—Ä—Ç –∫–Ω–∏–≥–∏ ID {book_id}...")

    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
    meta_response = supabase.table("books_full_view").select(
        "title, author, year, words, genre, set"
    ).eq("id", book_id).single().execute()

    if not meta_response.data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏.")
        return

    meta = meta_response.data
    title = meta.get("title", "")
    author = meta.get("author", "")
    year = meta.get("year", "")

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
    def fetch_json(field):
        response = supabase.table("books").select(
            field).eq("id", book_id).single().execute()
        return json.loads(response.data[field]) if response.data.get(field) else None

    original_text = fetch_json("text_by_chapters_sentence_translation_words")
    simplified_text = fetch_json(
        "text_by_chapters_simplified_sentence_translation_words")
    original_tasks = fetch_json("tasks_truefalse_howto_words")
    simplified_tasks = fetch_json("tasks_truefalse_howto_words_simplified")

    # üîß –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º –æ–¥–Ω—É –≥–ª–∞–≤—É —Å –æ–¥–Ω–∏–º –ø—É—Å—Ç—ã–º –∞–±–∑–∞—Ü–µ–º
    if not original_text:
        print("‚ö†Ô∏è –¢–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
        original_text = {
            "chapters": [{
                "chapter_number": 1,
                "paragraphs": [{
                    "paragraph_number": 1,
                    "sentences": []
                }]
            }]
        }

    # üåç –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∞–≤—Ç–æ—Ä–∞
    try:
        localized = fetch_localized_title_and_author(
            title, author, str(year), target_lang)
        localized_title = localized.localized_title
        localized_author = localized.localized_author
        print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ {target_lang}: {localized_title}")
        print(f"‚úÖ –ê–≤—Ç–æ—Ä –Ω–∞ {target_lang}: {localized_author}")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –∞–≤—Ç–æ—Ä–∞: {e}")
        localized_title = title
        localized_author = author

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    export_base = Path("export")
    export_base.mkdir(exist_ok=True)

    book_dir = export_base / f"book_{book_id}_{source_lang}"
    book_dir.mkdir(exist_ok=True)

    content_dir = book_dir / f"book_{book_id}_content"
    content_dir.mkdir(exist_ok=True)

    # –≠–∫—Å–ø–æ—Ä—Ç –ø–æ –≥–ª–∞–≤–∞–º
    for orig_ch in original_text["chapters"]:
        chapter_number = orig_ch["chapter_number"]
        simp_ch = next((c for c in (simplified_text or {}).get(
            "chapters", []) if c["chapter_number"] == chapter_number), {})
        task_ch = next((c for c in (original_tasks or {}).get(
            "chapters", []) if c["chapter_number"] == chapter_number), {})
        simp_task_ch = next((c for c in (simplified_tasks or {}).get(
            "chapters", []) if c["chapter_number"] == chapter_number), {})

        paragraphs = []
        for orig_p in orig_ch["paragraphs"]:
            para_num = orig_p["paragraph_number"]

            simp_p = next((p for p in simp_ch.get("paragraphs", [])
                          if p["paragraph_number"] == para_num), {})
            task_p = next((p for p in task_ch.get("paragraphs", [])
                          if p["paragraph_number"] == para_num), {})
            simp_task_p = next((p for p in simp_task_ch.get(
                "paragraphs", []) if p["paragraph_number"] == para_num), {})

            paragraphs.append({
                "paragraph_number": para_num,
                "sentences_original": orig_p.get("sentences", []),
                "sentences_simplified": simp_p.get("sentences", []),
                "tasks_original": {
                    "true_or_false": task_p.get("true_or_false"),
                    "how_to_translate": task_p.get("how_to_translate"),
                    "two_words": task_p.get("two_words")
                },
                "tasks_simplified": {
                    "true_or_false": simp_task_p.get("true_or_false"),
                    "how_to_translate": simp_task_p.get("how_to_translate"),
                    "two_words": simp_task_p.get("two_words")
                }
            })

        chapter_data = {
            "chapter_number": chapter_number,
            "paragraphs": paragraphs
        }

        chapter_path = content_dir / \
            f"book_{book_id}_chapter{chapter_number}_{source_lang}_{target_lang}.json"
        with open(chapter_path, "w", encoding="utf-8") as f:
            json.dump(chapter_data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≥–ª–∞–≤–∞: {chapter_path}")

    # üìÑ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    info_data = {
        "title": localized_title,
        "author": localized_author,
        "year": year,
        "words": meta.get("words"),
        "genre": meta.get("genre"),
        "set": meta.get("set"),
        "source_lang": source_lang,
        "target_lang": target_lang
    }

    info_path = book_dir / \
        f"book_{book_id}_info_{source_lang}_{target_lang}.json"
    with open(info_path, "w", encoding="utf-8") as f:
        json.dump(info_data, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–Ω–∏–≥–µ: {info_path}")


def fetch_localized_title_and_author(title: str, author: str, year: str, target_lang: str) -> LocalizedMeta:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    system_prompt = (
        f"–¢—ã –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. "
        f"–û–ø—Ä–µ–¥–µ–ª–∏, –ø–æ–¥ –∫–∞–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–Ω–∏–≥–∞ '{title}' –∞–≤—Ç–æ—Ä–∞ '{author}' {year} –≥–æ–¥–∞ "
        f"—á–∞—â–µ –≤—Å–µ–≥–æ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞—Å—å –Ω–∞ —è–∑—ã–∫–µ {target_lang}. "
        f"–¢–∞–∫–∂–µ –ø–µ—Ä–µ–≤–µ–¥–∏ –∏–º—è –∞–≤—Ç–æ—Ä–∞ –Ω–∞ —è–∑—ã–∫ {target_lang}, –µ—Å–ª–∏ –æ–Ω–æ –∏–º–µ–µ—Ç –æ–±—â–µ–ø—Ä–∏–Ω—è—Ç—ã–π –ø–µ—Ä–µ–≤–æ–¥. "
        f"–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON-–æ–±—ä–µ–∫—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å—Ö–µ–º–æ–π."
    )

    completion = client.beta.chat.completions.parse(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"title: {title}\nauthor: {author}\nyear: {year}"}
        ],
        response_format=LocalizedMeta,
    )

    return completion.choices[0].message.parsed
